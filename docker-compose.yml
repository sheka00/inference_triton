services:
  triton:
    image: nvcr.io/nvidia/tritonserver:24.01-py3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - ./models:/models
    command: tritonserver --model-repository=/models
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    healthcheck:
      test: ["CMD-SHELL", "curl -sSf http://localhost:8000/v2/health/ready || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s

  encoder:
    build:
      context: ./service
      dockerfile: Dockerfile
    environment:
      TRITON_URL: http://triton:8000
    ports:
      - "8080:8000"
    depends_on:
      triton:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -sSf http://localhost:8000/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
